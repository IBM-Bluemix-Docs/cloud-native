---

copyright:
  years: 2019
lastupdated: "2019-07-19"

---

{:new_window: target="_blank"}
{:shortdesc: .shortdesc}
{:screen: .screen}
{:codeblock: .codeblock}
{:pre: .pre}
{:tip: .tip}
{:note: .note}
{:important: .important}

# メトリック
{: #metrics}

メトリックとは、キーと値のペアとしてキャプチャーされる単純な数値指標です。 増分していくカウンターのメトリックもあれば、集約を行うメトリックもあります。例えば、過去 1 分間に収集されたすべての値の合計や過去 1 分間の平均経過時間などです。最後に観測された値を戻す、単純なゲージであるメトリックもあります。メトリックをキャプチャーして処理すると、悪化して深刻な問題になる前に、潜在的な問題を検出して対処することができます。
{:shortdesc}

分散システム内のメトリックには、プロデューサー、アグリゲーター、プロセッサーという 3 つの一般的な要素があります。これらの要素の組み合わせとして非常に人気があるのは、アグリゲーターとして Prometheus を使用し、収集したメトリックを Grafana で処理してグラフィカル・ダッシュボードで表示する方法です。StatsD と Graphite を併用する方法もあります。

![分散システムのメトリックの 3 つの要素](images/metrics-systems.png "分散システムのメトリックの 3 つの要素")

プロデューサーはアプリケーションです。一部のケースでは、アプリケーションがメトリックの生成に直接的に関与します。 他のケースでは、エージェントや他のインフラストラクチャーが、アプリケーションを受動的に観測するか積極的に計装して、アプリケーションの代わりにメトリックを生成します。 その次の処理は、アグリゲーターによって異なります。

メトリックは、「プッシュ」または「プル」メカニズムによってプロデューサーからアグリゲーターに転送されます。 StatsD などの一部のアグリゲーターは、アプリケーションがアグリゲーターに接続してデータを送信する必要があります。アグリゲーターの接続情報を、測定対象のすべてのアプリケーション・プロセスに分配する必要があります。Prometheus などのその他のアグリゲーターは、既知のエンドポイントに定期的に接続して、メトリック・データを収集します。このためには、収集できるエンドポイントをプロデューサーで定義して提供し、そのエンドポイントの場所をアグリゲーターに知らせる必要があります。 Kubernetes に使用する場合は、Prometheus はサービス注釈に基づいてエンドポイントを検出できます。

最後に、プロセッサーがすべての集約データを使用します。Grafana などのサービスが、集約されたメトリックを処理してダッシュボードで視覚化します。Grafana はルールを使用したアラートもサポートしています。アラートは、ダッシュボードとは無関係に保管され、評価されます。

## Kubernetes での Prometheus エンドポイントの自動検出
{: #prometheus-kubernetes}

プル・ベースのモデルでは、独自のエコシステムが作成されます。Sysdig などのその他のアグリゲーターも、Prometheus エンドポイントからメトリック・データを収集できます。 つまり、Prometheus サーバーを使用せずに Prometheus メトリックを使用するシステムにすることもできます。

Kubernetes 環境では、注釈を使用して Prometheus エンドポイントを検出できます。 例えば、ポート 8080 で HTTP による `/metrics` エンドポイントを提供するサービスは、以下の注釈をサービス定義に追加します。

```yaml
apiVersion: v1
kind: Service
metadata:
  name: ...
  annotations:
    prometheus.io/scrape: 'true'
    prometheus.io/scheme: http
    prometheus.io/path: /metrics
    prometheus.io/port: "8080"
  ...
```
{: codeblock}

そして、Prometheus 対応アグリゲーターで、Kubernetes API を使用して注釈をフィルタリングすれば、これらのエンドポイントを検出できます。

## アプリケーション・メトリックとプラットフォーム・メトリックの比較
{: #app-platform-metrics}

どのデータ・ポイントを収集するべきか検討する必要があります。クラウド・ネイティブ・アプリケーションを使用する場合は、アプリケーションとプラットフォームという 2 つのカテゴリーにメトリックを大まかに分けることができます。

* アプリケーション・メトリックは、アプリケーション領域のエンティティーに焦点を当てています。 例えば、過去 5 分間に実行されたログインの数、 現在接続しているユーザーの数、 過去 1 秒間で実行された取引の数などです。 アプリケーション固有のメトリックを集めるためには、情報を収集して公開するカスタム・コードが必要です。 ほとんどの言語には、カスタム・メトリックを簡単に追加できるようにメトリック・ライブラリーが用意されています。
* 一方、プラットフォーム・メトリックはホスティング領域のエンティティーです。 例えば、サービスの起動にかかった時間や、 データベース照会にかかった時間などです。 これらのメトリックは、システム内部のトラフィックや処理のフローを表し、多くの場合、アプリケーションを変更せずに測定できます。 このようなポイント (照会の実行時間など) を測定する機能を標準装備しているアプリケーション・フレームワークもあります。

測定すべきものを実際に決める際には、これらのカテゴリーだけでは不十分です。 分散システムでは、メトリックを生成するものが多く存在します。膨大なメトリック群から監視すべき少数の重要なメトリックを選び出すための、よく知られたメソッドをいくつか以下に示します。

* [4 大シグナル](https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/#xref_monitoring_golden-signals){: new_window} ![外部リンク・アイコン](../icons/launch-glyph.svg "外部リンク・アイコン") は、システムのモニターにおいて重要なメトリックです。これらは、Google の Site Reliability Engineering (SRE) チームが、モニターにおいてサービス・レベルの可観測性を確保するために決定したメトリックです。チームは、「ユーザーに提供するシステムのメトリックを 4 つしか測定できないとしたら、この 4 つのメトリックに焦点を当ててください。」と言っています。 4 つのメトリックとは、待ち時間、トラフィック、エラー、飽和です。
* [Utilization Saturation and Errors (USE) メソッド](http://www.brendangregg.com/usemethod.html){: new_window} ![外部リンク・アイコン](../icons/launch-glyph.svg "外部リンク・アイコン") は、システムのパフォーマンスを分析するための緊急チェックリストとして設計されています。 USE メソッドは「すべてのリソースについて、使用率、飽和、エラーを確認する」と一文に要約されています。 この場合、リソースは CPU やディスクなどのハードの制限のある物理リソースまたは論理リソースです。 有限リソースごとに、使用率、飽和、エラーを測定します。 
* [RED メソッド](https://thenewstack.io/monitoring-microservices-red-method/){: new_window} ![外部リンク・アイコン](../icons/launch-glyph.svg "外部リンク・アイコン") は、4 大シグナルから派生した簡易版であり、アーキテクチャー内のマイクロサービスごとに測定する 3 つの重要なメトリックを定義しています。このメソッドは、多数のクラウド・ネイティブ・アプリケーションの設計やアーキテクチャーに合わせられた USE メソッドと比較すると、非常に要求を重視するメソッドです。 メトリックは比率、エラー、期間です。 

USE メソッドは、インフラストラクチャーのメトリックに焦点を当てています。 クラウド・ネイティブ環境は、物理または仮想ハードウェアの利用効率を高めるように設計されています。 これらのインフラストラクチャー指標は、システムの負荷処理が適切かどうかを見るものです。 RED メソッドは、インフラストラクチャーとアプリケーションに関する問題を示す要求のメトリックに完全に焦点を合わせています。4 大シグナルは両方にまたがり、インフラストラクチャーのメトリックと要求のメトリックの両方を総合的に把握できるようにします。

## メトリックの定義
{: #defining-metrics}

単一のサービスから集められたメトリックをモニタリングする場合は、そのサービスのリソースの使用状況を理解できるかもしれません。しかし、サービスのインスタンスが複数存在する場合は、それらのインスタンスを区別し、送られてくる似たようなデータから問題を探し出す必要があります。結局は、命名方法が重要になります。 使用するメトリック・システムによって、メトリックの構造が決まってしまう場合もあります。 Prometheus は `namespace_subsystem_name` のような構造を推奨していますが、`namespace.subsystem.targetNoun.actioned` を推奨しているツールもあります。

例えば、株取引アプリケーションで実行された「取引」の数を追跡するのであれば、`stock.trades` というプロパティーにキャプチャーすると良いでしょう。 インスタンスを区別するには、このプロパティーの前にインスタンス ID を付けて `<instanceid>.stock.trades` とすることもできます。 こうすると、個々のインスタンスの値を収集できるうえに、`*.stock.trades` を使用してデータを集約することもできます。しかし、複数のデータ・センターにデプロイして同じ方法でメトリックを分析しようとすると、どうなるでしょうか? 名前を `<datacenter>.<instanceid>.stock.trades` に更新できますが、前述のワイルドカード `*.stock.trades` を使用した出力に問題が生じます。 代わりに、`*.*.stock.trades` を使用する必要があります。 

よく考えずに階層構造の名前のプロパティーを単独で使用すると、影響を受けやすいワイルドカード・パターンが、命名戦略の無作為な構造に結び付けられる可能性があります。影響を受けやすいワイルドカード・パターンでは、アプリケーションの正常な動作を確認するために必要な情報を観測できなくなる可能性があります。

ディメンション・データをサポートしているメトリック・システムを使用すると、識別ラベルまたはタグを関連付けることができます。一般的なラベルには、エンドポイント名またはサービス名、データ・センター、応答コード、ホスティング環境 (実稼働/ステージング/開発/テスト)、ランタイム識別子 (Java バージョン、アプリ・サーバー情報) が含まれます。

同じ株取引の例を使用すれば、`stock.trades` メトリックに複数のラベル `{ instanceid=..., datacenter=... }` などを関連付けます。これにより、ワイルドカードに頼らずに、集約値を `instanceid` または `datacenter` でフィルタリングしたりグループ化したりできるようになります。指定したメトリック `stock.trades` と、関連付けたラベルの間でバランスが取れています。ラベルで区別できるようにして、各メトリックで、意味のあるデータが収集されます。

ラベルは注意して定義してください。Prometheus では、キー/値のペアの固有の組み合わせごとに別個の時系列として扱われます。適切な照会動作および範囲を制限したデータ収集のためのベスト・プラクティスは、許可する値の数を制限してラベルを使用することです。 

エラーの数をカウントするメトリックを使用する場合は、値の数が妥当な範囲内にある戻りコードをラベルとして使用できます。失敗した URL をラベルに使用しないでください。数が無数にあるためです。

メトリックとラベルの命名に関するベスト・プラクティスについて詳しくは、[METRIC AND LABEL NAMING](https://prometheus.io/docs/practices/naming/){: new_window} ![外部リンク・アイコン](../icons/launch-glyph.svg "外部リンク・アイコン") を参照してください。

## その他の考慮事項
{: #metrics-considerations}

成功パスと大きく異なる失敗パスが多くあります。例えば、タイムアウトやスタック・トレース収集が関係する失敗では、成功応答と比べて、HTTP リソースに対するエラー応答に非常に時間がかかる可能性があります。 エラー・パスは、成功要求とは別にカウントして処理してください。

分散システムでは、自然な変動がある指標がいくつかあります。 起動やシャットダウンの最中にプロセスに要求が転送されたりするので、エラーがよく発生するのは普通です。 生データをフィルタリングして、この自然な変動が妥当な範囲を超えたのがいつであったかを調べてください。例えば、メトリックをバケットに分割します。 要求の期間を「最小/最速」、「中程度/通常」、「最長/最大」のようなカテゴリーに分類し、スライディング時間枠で観測します。 要求の期間が一貫して「最長/最大」バケットに該当する場合は、問題を識別できます。 この種のデータには通常はヒストグラムまたはサマリー・メトリックを使用します。 詳細については、[HISTOGRAMS AND SUMMARIES](https://prometheus.io/docs/practices/histograms/){: new_window} ![外部リンク・アイコン](../icons/launch-glyph.svg "外部リンク・アイコン") を参照してください。

アプリケーションまたはサービスが、業務のモニター作業の基礎になる組織全体の規約に従った名前とラベルのメトリックを出力するようにしてください。詳細については、[Monitoring Distributed Systems](https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems){: new_window} ![外部リンク・アイコン](../icons/launch-glyph.svg "外部リンク・アイコン") を参照してください。
