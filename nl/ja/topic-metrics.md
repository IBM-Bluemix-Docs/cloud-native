---

copyright:
  years: 2019
lastupdated: "2019-04-30"

---

{:new_window: target="_blank"}
{:shortdesc: .shortdesc}
{:screen: .screen}
{:codeblock: .codeblock}
{:pre: .pre}
{:tip: .tip}
{:note: .note}
{:important: .important}

# メトリック
{: #metrics}

メトリックとは、キーと値のペアとしてキャプチャーされる単純な数値指標です。 増分していくカウンターのメトリックもあれば、過去 1 分間に収集されたすべての値の合計や過去 1 分間の平均経過時間などの集約を行うメトリックもあります。 最後に観測された値を戻す、単純なゲージに過ぎないメトリックもあります。 メトリックをキャプチャーして処理すると、悪化して深刻な問題になる前に、潜在的な問題を検出して対処することができます。
{:shortdesc}

分散システム内のメトリックには、一般的に、プロデューサー、アグリゲーター、プロセッサーという 3 つの要素があります。 これらの要素の組み合わせとして非常に人気があるのは、アグリゲーターとして Prometheus を使用し、収集したメトリックを Grafana で処理してグラフィカル・ダッシュボードで表示する方法や、StatsD と Graphite を併用する方法です。

![分散システムのメトリックの 3 つの要素](images/metrics-systems.png "分散システムのメトリックの 3 つの要素"){: caption="図 1. 分散システムのメトリックの 3 つの要素" caption-side="bottom"}

プロデューサーは、当然、アプリケーション自体です。 一部のケースでは、アプリケーションがメトリックの生成に直接的に関与します。 他のケースでは、エージェントや他のインフラストラクチャーが、アプリケーションを受動的に観測するか積極的に計装して、アプリケーションの代わりにメトリックを生成します。 その次の処理は、アグリゲーターによって異なります。

メトリックは、「プッシュ」または「プル」メカニズムによってプロデューサーからアグリゲーターに転送されます。 StatsD などの一部のアグリゲーターは、アプリケーション (またはアプリケーションの代わりのエージェント) がアグリゲーターに接続してデータを送信する必要があります。 このためには、アグリゲーターの接続情報を、測定対象のすべてのアプリケーション・プロセスに分配する必要があります。 Prometheus などのその他のアグリゲーターは、既知のエンドポイントに定期的に接続して、メトリック・データを収集 (または取得) します。 このためには、収集できるエンドポイントをプロデューサーで定義して提供し、そのエンドポイントの場所をアグリゲーターに知らせる必要があります。 Kubernetes に使用する場合は、Prometheus はサービス注釈に基づいてエンドポイントを検出できます。

最後に、集約されたすべてのデータを使用するのがプロセッサーです。 前述のように、Grafana などのサービスが、集約されたメトリックを処理してダッシュボードに視覚化します。 Grafana はルールを使用したアラートもサポートしています。アラートは、ダッシュボードとは無関係に保管され、評価されます。

## Kubernetes での Prometheus エンドポイントの自動検出
{: #prometheus-kubernetes}

プル・ベースのモデルでは、独自のエコシステムが作成されています。 Sysdig などのその他のアグリゲーターも、Prometheus エンドポイントからメトリック・データを収集できます。 つまり、Prometheus サーバーを使用せずに Prometheus メトリックを使用するシステムにすることもできます。

Kubernetes 環境では、注釈を使用して Prometheus エンドポイントを検出できます。 例えば、ポート 8080 で HTTP による `/metrics` エンドポイントを提供するサービスは、以下の注釈をサービス定義に追加します。

```yaml
apiVersion: v1
kind: Service
metadata:
  name: ...
  annotations:
    prometheus.io/scrape: 'true'
    prometheus.io/scheme: http
    prometheus.io/path: /metrics
    prometheus.io/port: "8080"
  ...
```
{: codeblock}

そして、Prometheus 対応アグリゲーターで、Kubernetes API を使用して注釈をフィルタリングすれば、これらのエンドポイントを検出できます。

## アプリケーション・メトリックとプラットフォーム・メトリックの比較
{: #app-platform-metrics}

メトリックを収集する際には検討が必要です。 どのデータ・ポイントを収集するべきか検討する必要があります。 クラウド・ネイティブ・アプリケーションを検討している場合は、メトリックをアプリケーションとプラットフォームという 2 つのカテゴリーに大まかに分けることができます。

* アプリケーション・メトリックは、アプリケーション領域のエンティティーに焦点を当てています。 例えば、過去 5 分間に実行されたログインの数、 現在接続しているユーザーの数、 過去 1 秒間で実行された取引の数などです。 アプリケーション固有のメトリックを集めるためには、情報を収集して公開するカスタム・コードが必要です。 ほとんどの言語には、カスタム・メトリックを簡単に追加できるようにメトリック・ライブラリーが用意されています。
* 一方、プラットフォーム・メトリックはホスティング領域のエンティティーです。 例えば、サービスの起動にかかった時間や、 データベース照会にかかった時間などです。 これらのメトリックは、システム内部のトラフィックや処理のフローを表し、多くの場合、アプリケーションを変更せずに測定できます。 このようなポイント (照会の実行時間など) を測定する機能を標準装備しているアプリケーション・フレームワークもあります。

測定すべきものを自分で実際に決めるには、これらのカテゴリーだけでは不十分です。 分散システムでは、メトリックを生成するものが多いことを忘れないでください。 膨大なメトリック群から監視すべき少数の重要なメトリックを選び出すための、よく知られたメソッドをいくつか以下に示します。

* [4 大シグナル](https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/#xref_monitoring_golden-signals){: new_window} ![外部リンク・アイコン](../icons/launch-glyph.svg "外部リンク・アイコン") は、Google の Site Reliability Engineering (SRE) チームが、分散システムのモニターにおいてサービス・レベルの可観測性を確保するために重要なメトリックとして決定したメトリックです。 チームは、「ユーザーに提供するシステムのメトリックを 4 つしか測定できないとしたら、この 4 つのメトリックに焦点を当ててください。」と言っています。 4 つのメトリックとは、待ち時間、トラフィック、エラー、飽和です。
* [Utilization Saturation and Errors (USE) メソッド](http://www.brendangregg.com/usemethod.html){: new_window} ![外部リンク・アイコン](../icons/launch-glyph.svg "外部リンク・アイコン") は、システムのパフォーマンスを分析するための緊急チェックリストとして設計されています。 USE メソッドは「すべてのリソースについて、使用率、飽和、エラーを確認する」と一文に要約されています。 この場合、リソースは CPU やディスクなどのハードの制限のある物理リソースまたは論理リソースです。 有限リソースごとに、使用率、飽和、エラーを測定します。 
* [RED メソッド](https://thenewstack.io/monitoring-microservices-red-method/){: new_window} ![外部リンク・アイコン](../icons/launch-glyph.svg "外部リンク・アイコン") は、4 大シグナルから派生した簡易版であり、アーキテクチャー内のマイクロサービスごとに測定する必要がある 3 つの重要なメトリックを定義しています。 このメソッドは、特に、多数のクラウド・ネイティブ・アプリケーションの設計やアーキテクチャーに合わせられた USE メソッドと比較すると、非常に要求を重視するメソッドです。 メトリックは比率、エラー、期間です。 

これらのメソッドに共通するエレメントがいくつかあります。例えば、すべてのメソッドがエラー率を追跡します。 ただし、注目すべき違いもあります。 USE メソッドは、インフラストラクチャーのメトリック (使用率/飽和) に焦点を当てています。 クラウド・ネイティブ環境は、物理 (または仮想) ハードウェアの利用効率を高めるように設計されています。 これらのインフラストラクチャー指標は、システムの負荷処理が適切かどうかを見るものです。 RED メソッドは、完全に要求のメトリック (待ち時間/期間、トラフィック/速度) に焦点を当てています。特にエラー率の観測と組み合わせると、インフラストラクチャーの問題 (ネットワーク問題) やアプリケーションの問題 (構成の誤り、デッドロック、サービスの失敗の繰り返しなど) を示すことができます。 4 大シグナルは両方にまたがり、インフラストラクチャーのメトリックと要求のメトリックの両方を総合的に把握できるようにします。

## メトリックの定義
{: #defining-metrics}

単一のサービスから集められたメトリックをモニタリングすれば、そのサービスのリソースの使用状況を理解できるかもしれませんが、(水平スケーリングまたは複数領域デプロイメントで) サービスのインスタンスが複数存在する場合は、それらのインスタンスを区別し、送られてくる大量の類似データから問題を探し出す必要があります。 結局は、命名方法が重要になります。 使用するメトリック・システムによって、メトリックの構造が決まってしまう場合もあります。 Prometheus のように `namespace_subsystem_name` のような構造が推奨されるものもあれば、`namespace.subsystem.targetNoun.actioned` が推奨されるツールもあります。

例えば、株取引アプリケーションで実行された「取引」の数を追跡するのであれば、`stock.trades` というプロパティーにキャプチャーすると良いでしょう。 インスタンスを区別するには、このプロパティーの前にインスタンス ID を付けて `<instanceid>.stock.trades` とすることもできます。 こうすると、個々のインスタンスの値を収集できるうえに、`*.stock.trades` を使用してデータを集約することもできます。 しかし、複数のデータ・センターにデプロイして同じ方法でメトリックを分析しようとすると、どうなるでしょうか? 名前を `<datacenter>.<instanceid>.stock.trades` に更新できますが、前述のワイルドカード `*.stock.trades` を使用した出力に問題が生じます。 代わりに、`*.*.stock.trades` を使用する必要があります。 

よく考えずに階層構造の名前のプロパティーを単独で使用すると、影響を受けやすいワイルドカード・パターンが、命名戦略の予期せぬ構造に結び付けられ、アプリケーションの正常な動作を確認するために必要な情報を観測できなくなる可能性があります。

ディメンション・データをサポートしているメトリック・システムを使用すると、追加の識別ラベル (タグ) をメトリック・データと関連付けることができます。 そうすれば、ワイルドカードや命名規則に頼らずに、それらの追加のディメンションを使用して、収集されたメトリックのフィルタリング、グループ化、分析を実行できます。 一般的なラベルには、エンドポイント名またはサービス名、データ・センター、応答コード、ホスティング環境 (実稼働/ステージング/開発/テスト)、ランタイム識別子 (Java バージョン、アプリ・サーバー情報) が含まれます。

同じ株取引の例を使用すると、`stock.trades` メトリックに複数のラベル `{ instanceid=..., datacenter=... }` を関連付ければ、ワイルドカードに頼らずに集約値を `instanceid` または `datacenter` でフィルタリングしたりグループ化したりできます。 名前を付けたメトリック (`stock.trades`) と関連付けられたラベルのバランスが取れています (階層型の `<datacenter>.<instanceid>.stock.trades` の例と比較してください)。該当する場所をラベルで区別して、各メトリックで意味のあるデータがキャプチャーされます。

また、ラベルの定義にも注意してください。 例えば Prometheus では、ラベルのキー/値のペアの固有の組み合わせはすべて別の時系列として扱われます。 適切な照会動作および範囲を制限したデータ収集のためのベスト・プラクティスは、許可する値の数を制限してラベルを使用することです。 例えば、エラーの数をカウントするメトリックを使用する場合は、戻りコードをラベルとして使用できます。値 (401、404、409、500、... ) の数が妥当な範囲内にあるからです。しかし、失敗した URL をラベルに使用することはお勧めしません。値 (無効であるなどの理由で失敗したあらゆる要求 URL) の数が無数にあるからです。

メトリックとラベルの命名に関するベスト・プラクティスについて詳しくは、[METRIC AND LABEL NAMING](https://prometheus.io/docs/practices/naming/){: new_window} ![外部リンク・アイコン](../icons/launch-glyph.svg "外部リンク・アイコン") を参照してください。

## 追加の考慮事項
{: #metrics-considerations}

メトリックを収集する場合は、成功パスと大きく異なる失敗パスが多いことに注意してください。 例えば、タイムアウトやスタック・トレース収集が関係する失敗では、成功応答と比べて、HTTP リソースに対するエラー応答に非常に時間がかかる可能性があります。 エラー・パスは、成功要求とは別にカウントして処理してください。

分散システムでは、自然な変動がある指標がいくつかあります。 起動やシャットダウンの最中にプロセスに要求が転送されたりするので、エラーがよく発生するのは普通です。 生データをフィルタリングして、この自然な変動が妥当な範囲を超え始めたのがいつであったかを調べてください。 例えば、メトリックをバケットに分割します。 要求の期間を「最小/最速」、「中程度/通常」、「最長/最大」のようなカテゴリーに分類し、スライディング時間枠で観測します。 要求の期間が一貫して「最長/最大」バケットに該当する場合は、問題を識別できます。この種のデータには通常はヒストグラムまたはサマリー・メトリックを使用します。 詳細については、[HISTOGRAMS AND SUMMARIES](https://prometheus.io/docs/practices/histograms/){: new_window} ![外部リンク・アイコン](../icons/launch-glyph.svg "外部リンク・アイコン") を参照してください。

アプリケーション開発者は、ご使用のアプリケーションまたはサービスが、組織の規模の規則に従った名前とラベルのメトリックを出力し、業務の中心となるエンドツーエンドのパスに集中したモニター作業をサポートしていることを確認してください。 詳細については、[Monitoring Distributed Systems](https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/){: new_window} ![外部リンク・アイコン](../icons/launch-glyph.svg "外部リンク・アイコン") を参照してください。
